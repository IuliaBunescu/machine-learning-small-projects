{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection for ML MOOC Challenge\n",
    "## Object Detection using YOLOv8, Roboflow and Google Colab\n",
    "#### Author: Julia Bunescu\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>     \n",
    "- [The Challenge](#toc1_2_)    \n",
    "- [Model Selection](#toc1_3_)    \n",
    "- [Testing the Pretrained Model](#toc1_4_)    \n",
    "- [Custom Training dataset](#toc1_5_)    \n",
    "  - [Preparing the dataset](#toc1_5_1_)    \n",
    "  - [Importing the Dataset](#toc1_5_2_)    \n",
    "  - [Training the model](#toc1_5_3_)    \n",
    "  - [Validating the model](#toc1_5_4_)    \n",
    "  - [Testing the model](#toc1_5_5_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[The Challenge](#toc0_)\n",
    "\n",
    "We are going to be identifying objects within a series of images. The objects we need to identify are:\n",
    "\n",
    "\t- Phone, \n",
    "\t- Laptop, \n",
    "\t- USB stick, \n",
    "\t- Keyboard\n",
    "\t- Router, \n",
    "\t- Keys, \n",
    "\t- Server rack, \n",
    "\t- Mouse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goals are:\n",
    "- [x]  The objective would be to identify these items explicitly in any image.\n",
    "- [x]  A bonus goal would be to determine the number of each of these items in a picture.\n",
    "- [ ]  Final super-bonus objective would be identifying other items outside of the list and reporting back. (*future work*)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Model Selection](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model chosen for the implementation was YOLO. The latest version of the model is called [YOLOv8](https://github.com/ultralytics/ultralytics) and it was chosen for because it is fast, accurate, and easy to implement in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.105  Python-3.10.4 torch-2.0.1+cpu CPU\n",
      "Setup complete  (16 CPUs, 15.4 GB RAM, 452.9/934.7 GB disk)\n"
     ]
    }
   ],
   "source": [
    "# checking and installing missing packages\n",
    "%pip install ultralytics\n",
    "%pip install IPython\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Testing the Pretrained Model](#toc0_)\n",
    "\n",
    "Using a pretrained YOLO model to check the performance on the test image. The model was trained on the [COCO](https://cocodataset.org/#home) dataset, and is able to distinguish between 80 object categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\iulia\\Documents\\Projects\\machine-learning-small-projects\\test_images\\Test Example.png: 416x640 1 person, 1 apple, 3 mouses, 182.1ms\n",
      "Speed: 7.4ms preprocess, 182.1ms inference, 12.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"../models/yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "results = model.predict(source=\"../test_images/Test Example.png\", conf=0.6, save=True, retina_masks=True) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "Using the pretrained model with a minimum confidence level of 60%, we are able to detect some of the target objects, but not all of them. We can see the results of the detection here:\n",
    "<center><img src=\"../results_images/challenge_test_default_model.png\" width=\"800\" /><center/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Custom Training dataset](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_1_'></a>[Preparing the dataset](#toc0_)\n",
    "\n",
    "A custon dataset was created using [Roboflow](https://universe.roboflow.com/iulia-bunescu-vldcs/specific-electronics-challenge-v2).\n",
    "The images for the this dataset were gathered using [Fatkun Batch Download Image](https://microsoftedge.microsoft.com/addons/detail/fatkun-batch-download-ima/dammmokdamnimedflemdaoamhldmldff?hl=en-US) Edge extension, where .png and .jpg formats were selected. The results were also filtered decreasingly by size.\n",
    "\n",
    "After several iterations, the final version of the datset was preprocessed and augmented as following: resized to fit within $1240$ x $720$ with white edges, added rotation between $-15\\degree$ and $15\\degree$, and $25\\%$ of the training datat was grayscaled.\n",
    "\n",
    "The distribution of the labels on the final dataset can be seen below.\n",
    "\n",
    "<center><img src=\"../results_images/label_distribution.jpg\" width=\"400\" /><center/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_2_'></a>[Importing the Dataset](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install roboflow --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The api key below was removed due to privacy issues. Please go ahead and export the public model by generating your own key [here](https://universe.roboflow.com/iulia-bunescu-vldcs/specific-electronics-challenge-v2/dataset/7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics<=8.0.20 is required but found version=8.0.105, to fix: `pip install ultralytics<=8.0.20`\n",
      "Downloading Dataset Version Zip in Specific-Electronics-Challenge-v2-7 to yolov8: 100% [148027312 / 148027312] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Specific-Electronics-Challenge-v2-7 in yolov8:: 100%|██████████| 4398/4398 [00:03<00:00, 1119.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# download the custom dataset from Roboflow\n",
    "rf = Roboflow(api_key=\"$$$$$$$$$$$$$$\")\n",
    "project = rf.workspace(\"iulia-bunescu-vldcs\").project(\"specific-electronics-challenge-v2\")\n",
    "dataset = project.version(7).download(\"yolov8\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_3_'></a>[Training the model](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training was done using **Google Colab**. The platform was chosen due to its GPU feature. \n",
    "\n",
    "Below you can find the commands used for training. As it can be seen, the model was trained for just *30 epochs*, which can be of course increased to obtain better results. However, the obtained model satisfies the requirements of this application, hence the training was stopped there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"../models/yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model to train on the custon\n",
    "model.train(data='/content/electronics-part-2-7/data.yaml', epochs =30, save_period = 1, imgsz =[720,1240])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_4_'></a>[Validating the model](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation was done after training. Below you can find some of the predictions made in the process:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../results_images/val_batch0_pred.jpg\" width=\"50%\" /> <img src=\"../results_images/val_batch1_pred.jpg\" width=\"50%\" /><center/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can also see the results of the validating metrics. While the model behaves well for most of the object classes, *phones, servers, and keys* have room for improvement."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../results_images/confusion_matrix_normalized.png\" width=\"800\"/> <center/>\n",
    "<center> <img src=\"../results_images/PR_curve.png\" width=\"800\"/><center/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_5_'></a>[Testing the model](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model 3 images: first the test image from the challenge, then a custom image contaning objects from classes which are not in the first, and lastly a more organic environment contaning a laptop setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pretrained model\n",
    "model = YOLO(\"../models/dataset2_7.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\iulia\\Documents\\Projects\\machine-learning-small-projects\\test_images\\Test Example.png: 800x1248 3 mouses, 4 servers, 1 usb stick, 295.1ms\n",
      "Speed: 11.0ms preprocess, 295.1ms inference, 2.0ms postprocess per image at shape (1, 3, 1248, 1248)\n",
      "Results saved to \u001b[1mruns\\detect\\predict34\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Challenge image\n",
    "results = model.predict(source=\"../test_images/Test Example.png\", conf=0.5, save=True, retina_masks=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../results_images/challenge_test_trained_model.png\" width=\"800\" /><center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\iulia\\Documents\\Projects\\machine-learning-small-projects\\test_images\\test_2.png: 704x1248 1 keyboard, 1 keys, 1 phone, 1 router, 263.2ms\n",
      "Speed: 10.0ms preprocess, 263.2ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1248)\n",
      "Results saved to \u001b[1mruns\\detect\\predict34\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Custom made image\n",
    "results = model.predict(source=\"../test_images/test_2.png\", conf=0.5, save=True, retina_masks=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../results_images/test_2.png\" width=\"800\" /><center/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\iulia\\Documents\\Projects\\machine-learning-small-projects\\test_images\\Laptop-Desk-Setup.jpg: 768x1248 1 keyboard, 1 laptop, 1 mouse, 285.6ms\n",
      "Speed: 12.0ms preprocess, 285.6ms inference, 1.0ms postprocess per image at shape (1, 3, 1248, 1248)\n",
      "Results saved to \u001b[1mruns\\detect\\predict34\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Organic scenary image\n",
    "results = model.predict(source=\"../test_images/Laptop-Desk-Setup.jpg\", conf=0.5, save=True, retina_masks=True) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../results_images/Laptop-Desk-Setup.jpg\" width=\"800\" /><center/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
